{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "abalone = fetch_ucirepo(id=1) \n",
    "  \n",
    "# data (as pandas dataframes)\n",
    "orig_train = pd.concat([abalone.data.features, abalone.data.targets], axis = 1).rename({\n",
    "    'Whole_weight' : 'Whole weight',\n",
    "    'Shucked_weight' : 'Whole weight.1',\n",
    "    'Viscera_weight' : 'Whole weight.2',\n",
    "    'Shell_weight' : 'Shell weight'\n",
    "}, axis = 1)\n",
    "orig_train.to_csv('original_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'train.csv', index_col = 'id')\n",
    "test = pd.read_csv(r'test.csv', index_col = 'id')\n",
    "submission = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, orig_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats(df):\n",
    "#     df['WW1_Ratio'] = df['Whole weight.1'] / df['Whole weight']\n",
    "#     df['WW2_Ratio'] = df['Whole weight.2'] / df['Whole weight']\n",
    "#     df['Shell_Ratio'] = df['Shell weight'] / df['Whole weight']\n",
    "#     df['ProxyVolume'] = 2 * np.log1p(df[\"Diameter\"]) +  np.log1p(df[\"Height\"])\n",
    "    df['Height']=np.where(df['Height']==0, 0.005, df['Height'])\n",
    "    return df\n",
    "\n",
    "train = feats(train)\n",
    "test = feats(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1330\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.718698\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's rmse: 1.8389\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1330\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.698588\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\tvalid_0's rmse: 1.87212\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1330\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.711831\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's rmse: 1.82477\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1332\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.718833\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's rmse: 1.77507\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1329\n",
      "[LightGBM] [Info] Number of data points in the train set: 75834, number of used features: 8\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 9.688214\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's rmse: 1.88225\n",
      "The number of candidate features is 322\n",
      "Start stage I selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:19<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 same features have been deleted.\n",
      "The number of remaining candidate features is 78\n",
      "Start stage II selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:06<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish data processing.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19412\n",
      "[LightGBM] [Info] Number of data points in the train set: 75833, number of used features: 86\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Whole weight.1</th>\n",
       "      <th>Whole weight.2</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>autoFE_f_0</th>\n",
       "      <th>autoFE_f_1</th>\n",
       "      <th>autoFE_f_2</th>\n",
       "      <th>autoFE_f_3</th>\n",
       "      <th>autoFE_f_4</th>\n",
       "      <th>autoFE_f_5</th>\n",
       "      <th>autoFE_f_6</th>\n",
       "      <th>autoFE_f_7</th>\n",
       "      <th>autoFE_f_8</th>\n",
       "      <th>autoFE_f_9</th>\n",
       "      <th>autoFE_f_10</th>\n",
       "      <th>autoFE_f_11</th>\n",
       "      <th>autoFE_f_12</th>\n",
       "      <th>autoFE_f_13</th>\n",
       "      <th>autoFE_f_14</th>\n",
       "      <th>autoFE_f_15</th>\n",
       "      <th>autoFE_f_16</th>\n",
       "      <th>autoFE_f_17</th>\n",
       "      <th>autoFE_f_18</th>\n",
       "      <th>autoFE_f_19</th>\n",
       "      <th>autoFE_f_20</th>\n",
       "      <th>autoFE_f_21</th>\n",
       "      <th>autoFE_f_22</th>\n",
       "      <th>autoFE_f_23</th>\n",
       "      <th>autoFE_f_24</th>\n",
       "      <th>autoFE_f_25</th>\n",
       "      <th>autoFE_f_26</th>\n",
       "      <th>autoFE_f_27</th>\n",
       "      <th>autoFE_f_28</th>\n",
       "      <th>autoFE_f_29</th>\n",
       "      <th>autoFE_f_30</th>\n",
       "      <th>autoFE_f_31</th>\n",
       "      <th>autoFE_f_32</th>\n",
       "      <th>autoFE_f_33</th>\n",
       "      <th>autoFE_f_34</th>\n",
       "      <th>autoFE_f_35</th>\n",
       "      <th>autoFE_f_36</th>\n",
       "      <th>autoFE_f_37</th>\n",
       "      <th>autoFE_f_38</th>\n",
       "      <th>autoFE_f_39</th>\n",
       "      <th>autoFE_f_40</th>\n",
       "      <th>autoFE_f_41</th>\n",
       "      <th>autoFE_f_42</th>\n",
       "      <th>autoFE_f_43</th>\n",
       "      <th>autoFE_f_44</th>\n",
       "      <th>autoFE_f_45</th>\n",
       "      <th>autoFE_f_46</th>\n",
       "      <th>autoFE_f_47</th>\n",
       "      <th>autoFE_f_48</th>\n",
       "      <th>autoFE_f_49</th>\n",
       "      <th>autoFE_f_50</th>\n",
       "      <th>autoFE_f_51</th>\n",
       "      <th>autoFE_f_52</th>\n",
       "      <th>autoFE_f_53</th>\n",
       "      <th>autoFE_f_54</th>\n",
       "      <th>autoFE_f_55</th>\n",
       "      <th>autoFE_f_56</th>\n",
       "      <th>autoFE_f_57</th>\n",
       "      <th>autoFE_f_58</th>\n",
       "      <th>autoFE_f_59</th>\n",
       "      <th>autoFE_f_60</th>\n",
       "      <th>autoFE_f_61</th>\n",
       "      <th>autoFE_f_62</th>\n",
       "      <th>autoFE_f_63</th>\n",
       "      <th>autoFE_f_64</th>\n",
       "      <th>autoFE_f_65</th>\n",
       "      <th>autoFE_f_66</th>\n",
       "      <th>autoFE_f_67</th>\n",
       "      <th>autoFE_f_68</th>\n",
       "      <th>autoFE_f_69</th>\n",
       "      <th>autoFE_f_70</th>\n",
       "      <th>autoFE_f_71</th>\n",
       "      <th>autoFE_f_72</th>\n",
       "      <th>autoFE_f_73</th>\n",
       "      <th>autoFE_f_74</th>\n",
       "      <th>autoFE_f_75</th>\n",
       "      <th>autoFE_f_76</th>\n",
       "      <th>autoFE_f_77</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>2672.0</td>\n",
       "      <td>2.348554</td>\n",
       "      <td>1.368750</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>-0.0935</td>\n",
       "      <td>0.157544</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>2.242321</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>340.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>0.035397</td>\n",
       "      <td>3.214583</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.243335</td>\n",
       "      <td>5.266212</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>0.141255</td>\n",
       "      <td>0.278630</td>\n",
       "      <td>2.935154</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>2.1400</td>\n",
       "      <td>0.7715</td>\n",
       "      <td>0.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2015</td>\n",
       "      <td>0.062995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6965</td>\n",
       "      <td>0.610417</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.049275</td>\n",
       "      <td>0.106898</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>-1.427116</td>\n",
       "      <td>0.9180</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>-0.3415</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>0.215506</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.115725</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.253438</td>\n",
       "      <td>0.6700</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.575</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>1.1375</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.1300</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>2.467249</td>\n",
       "      <td>1.431250</td>\n",
       "      <td>0.6720</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.565685</td>\n",
       "      <td>-0.0435</td>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>4.344828</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>1.656420</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.3535</td>\n",
       "      <td>86.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>0.7665</td>\n",
       "      <td>0.7780</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.956930</td>\n",
       "      <td>4.086799</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>0.224420</td>\n",
       "      <td>0.715119</td>\n",
       "      <td>1.772152</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>1.8075</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6200</td>\n",
       "      <td>0.135485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.864063</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.433628</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.066410</td>\n",
       "      <td>0.963678</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>-1.139434</td>\n",
       "      <td>1.4065</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>-0.6400</td>\n",
       "      <td>0.4695</td>\n",
       "      <td>0.649572</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.174195</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.0880</td>\n",
       "      <td>0.163850</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.517540</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.5880</td>\n",
       "      <td>1.4500</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>499.0</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.155689</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>102.0</td>\n",
       "      <td>-0.0200</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.022114</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.344311</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>-0.0220</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.02100</td>\n",
       "      <td>5.238095</td>\n",
       "      <td>-0.9950</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.00550</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-5.298317</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.1155</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>2.435419</td>\n",
       "      <td>1.502000</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.0445</td>\n",
       "      <td>0.322763</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>3.966667</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3450</td>\n",
       "      <td>1.827251</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>379.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.035397</td>\n",
       "      <td>3.658000</td>\n",
       "      <td>0.6805</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.349879</td>\n",
       "      <td>4.450122</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.178362</td>\n",
       "      <td>0.682618</td>\n",
       "      <td>2.311436</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>2.1400</td>\n",
       "      <td>0.9145</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>1.3895</td>\n",
       "      <td>0.097612</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.148750</td>\n",
       "      <td>0.45725</td>\n",
       "      <td>0.519410</td>\n",
       "      <td>-1.7500</td>\n",
       "      <td>0.2695</td>\n",
       "      <td>0.18775</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.056325</td>\n",
       "      <td>0.389820</td>\n",
       "      <td>0.8450</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>-1.386294</td>\n",
       "      <td>1.1200</td>\n",
       "      <td>0.3755</td>\n",
       "      <td>-0.4395</td>\n",
       "      <td>0.4405</td>\n",
       "      <td>0.440061</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.122272</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.137175</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>0.343395</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.575</td>\n",
       "      <td>1.2900</td>\n",
       "      <td>1.1645</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.1375</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.116373</td>\n",
       "      <td>1.870886</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.444410</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.835659</td>\n",
       "      <td>0.025675</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>4.269231</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>2.309375</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>382.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>3.959494</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.508903</td>\n",
       "      <td>4.887500</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.157037</td>\n",
       "      <td>0.897435</td>\n",
       "      <td>2.656250</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>1.5560</td>\n",
       "      <td>0.7820</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>1.2070</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.109613</td>\n",
       "      <td>0.78200</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>-0.8025</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.36950</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.048035</td>\n",
       "      <td>0.721447</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>-1.622017</td>\n",
       "      <td>0.9420</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>-0.3570</td>\n",
       "      <td>0.3950</td>\n",
       "      <td>0.908312</td>\n",
       "      <td>0.7945</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>0.101660</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.288949</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.1515</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.1975</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  Shell weight  \\\n",
       "0    0   0.550     0.430   0.150        0.7715          0.3285          0.1465        0.2400   \n",
       "1    0   0.630     0.490   0.145        1.1300          0.4580          0.2765        0.3200   \n",
       "2    1   0.160     0.110   0.025        0.0210          0.0055          0.0030        0.0050   \n",
       "3    2   0.595     0.475   0.150        0.9145          0.3755          0.2055        0.2500   \n",
       "4    1   0.555     0.425   0.130        0.7820          0.3695          0.1600        0.1975   \n",
       "\n",
       "   autoFE_f_0  autoFE_f_1  autoFE_f_2  autoFE_f_3  autoFE_f_4  autoFE_f_5  autoFE_f_6  autoFE_f_7  \\\n",
       "0      2672.0    2.348554    1.368750      0.4430      0.0885    0.489898     -0.0935    0.157544   \n",
       "1      1204.0    2.467249    1.431250      0.6720      0.1380    0.565685     -0.0435    0.837460   \n",
       "2       499.0    3.818182    1.100000      0.0155      0.0005    0.070711     -0.0020    0.155689   \n",
       "3      2130.0    2.435419    1.502000      0.5390      0.1255    0.500000     -0.0445    0.322763   \n",
       "4        34.0    2.116373    1.870886      0.4125      0.1720    0.444410     -0.0375    0.835659   \n",
       "\n",
       "   autoFE_f_8  autoFE_f_9  autoFE_f_10  autoFE_f_11  autoFE_f_12  autoFE_f_13  autoFE_f_14  \\\n",
       "0    0.036000       136.0       0.0900     3.666667       0.2400       0.3100     2.242321   \n",
       "1    0.046400        88.0       0.1750     4.344828       0.3200       0.3100     1.656420   \n",
       "2    0.000125       102.0      -0.0200     6.400000       0.0050       0.1550     1.833333   \n",
       "3    0.037500       112.0       0.1000     3.966667       0.2500       0.3450     1.827251   \n",
       "4    0.025675        86.0       0.0675     4.269231       0.1975       0.3575     2.309375   \n",
       "\n",
       "   autoFE_f_15  autoFE_f_16  autoFE_f_17  autoFE_f_18  autoFE_f_19  autoFE_f_20  autoFE_f_21  \\\n",
       "0       0.1900       0.4035        340.0        601.0     0.035397     3.214583       0.5765   \n",
       "1       0.1700       0.3535         86.0         40.0     0.035333     3.531250       0.7665   \n",
       "2       0.1050       0.1570         58.0         65.0     0.022114     4.200000       0.1130   \n",
       "3       0.2250       0.3895        379.0        102.0     0.035397     3.658000       0.6805   \n",
       "4       0.2275       0.3950        382.0        588.0     0.038715     3.959494       0.5850   \n",
       "\n",
       "   autoFE_f_22  autoFE_f_23  autoFE_f_24  autoFE_f_25  autoFE_f_26  autoFE_f_27  autoFE_f_28  \\\n",
       "0       0.5685       0.2400     0.243335     5.266212       0.2400      -0.0035     0.141255   \n",
       "1       0.7780       0.3200     0.956930     4.086799       0.3200       0.1315     0.224420   \n",
       "2       0.0105       0.0050     0.344311     7.000000       0.0050      -0.0220     0.000605   \n",
       "3       0.6255       0.2500     0.349879     4.450122       0.2500       0.0555     0.178362   \n",
       "4       0.5670       0.1975     0.508903     4.887500       0.1975       0.0300     0.157037   \n",
       "\n",
       "   autoFE_f_29  autoFE_f_30  autoFE_f_31  autoFE_f_32  autoFE_f_33  autoFE_f_34  autoFE_f_35  \\\n",
       "0     0.278630     2.935154       0.1465       2.1400       0.7715        0.700          NaN   \n",
       "1     0.715119     1.772152       0.2765       1.8075       0.1300        0.775          NaN   \n",
       "2     0.004640    36.666667       0.0030       0.0545       0.0210        0.185       0.1600   \n",
       "3     0.682618     2.311436       0.2055       2.1400       0.9145        0.745       0.2975   \n",
       "4     0.897435     2.656250       0.1600       1.5560       0.7820        0.685       0.5550   \n",
       "\n",
       "   autoFE_f_36  autoFE_f_37  autoFE_f_38  autoFE_f_39  autoFE_f_40  autoFE_f_41  autoFE_f_42  \\\n",
       "0       1.2015     0.062995          NaN       0.6965     0.610417     0.132000          NaN   \n",
       "1       1.6200     0.135485          NaN       0.9065     0.864063     0.201600          NaN   \n",
       "2       0.1310     0.000330       0.0050       0.1630     0.600000     0.000800      0.02100   \n",
       "3       1.3895     0.097612       0.1250       0.8005     0.822000     0.148750      0.45725   \n",
       "4       1.2070     0.068000       0.1975       0.7150     0.810127     0.109613      0.78200   \n",
       "\n",
       "   autoFE_f_43  autoFE_f_44  autoFE_f_45  autoFE_f_46  autoFE_f_47  autoFE_f_48  autoFE_f_49  \\\n",
       "0     0.557356       0.2400       0.2835          NaN        0.725     0.049275     0.106898   \n",
       "1     0.433628       0.3200       0.2135          NaN        0.720     0.066410     0.963678   \n",
       "2     5.238095      -0.9950       0.1070      0.00550        0.215     0.000138     0.514970   \n",
       "3     0.519410      -1.7500       0.2695      0.18775        0.725     0.056325     0.389820   \n",
       "4     0.543478      -0.8025       0.2650      0.36950        0.740     0.048035     0.721447   \n",
       "\n",
       "   autoFE_f_50  autoFE_f_51  autoFE_f_52  autoFE_f_53  autoFE_f_54  autoFE_f_55  autoFE_f_56  \\\n",
       "0       0.7900        0.550       0.3285    -1.427116       0.9180       0.3285      -0.3415   \n",
       "1       0.9500        0.630       0.4580    -1.139434       1.4065       0.4580      -0.6400   \n",
       "2       0.1650        0.160       0.0055    -5.298317       0.0240       0.0250       0.0890   \n",
       "3       0.8450        0.595       0.3755    -1.386294       1.1200       0.3755      -0.4395   \n",
       "4       0.7525        0.555       0.3695    -1.622017       0.9420       0.3695      -0.3570   \n",
       "\n",
       "   autoFE_f_57  autoFE_f_58  autoFE_f_59  autoFE_f_60  autoFE_f_61  autoFE_f_62  autoFE_f_63  \\\n",
       "0       0.4405     0.215506       0.7585     0.080575         0.24       0.8785     0.115725   \n",
       "1       0.4695     0.649572       0.9480     0.174195         0.32       1.0880     0.163850   \n",
       "2       0.0125     0.008107       0.1155     0.000480         1.00       0.1655     0.000525   \n",
       "3       0.4405     0.440061       0.8505     0.122272         2.00       0.9705     0.137175   \n",
       "4       0.3950     0.908312       0.7945     0.088800         1.00       0.9245     0.101660   \n",
       "\n",
       "   autoFE_f_64  autoFE_f_65  autoFE_f_66  autoFE_f_67  autoFE_f_68  autoFE_f_69  autoFE_f_70  \\\n",
       "0        0.430       0.2400          1.0       0.1465       0.1465     0.253438       0.6700   \n",
       "1        0.490       0.3200          1.0       0.2765       0.2765     0.517540       0.8100   \n",
       "2        0.021       0.0050          1.0       0.0030       0.0030     0.000116       0.1150   \n",
       "3        0.475       0.2500          1.0       0.2055       0.2055     0.343395       0.7250   \n",
       "4        0.425       0.1975          1.0       0.1600       0.1600     0.288949       0.6225   \n",
       "\n",
       "   autoFE_f_71  autoFE_f_72  autoFE_f_73  autoFE_f_74  autoFE_f_75  autoFE_f_76  autoFE_f_77  \\\n",
       "0       0.2400       0.2400        0.575       1.1000       1.0115       0.2400       1.1375   \n",
       "1       0.3200       0.3200        0.585       1.5880       1.4500       0.3200       0.8760   \n",
       "2       0.0050       0.0250        0.185       0.0265       0.0260       0.0050       0.0240   \n",
       "3       0.2500       0.2500        0.575       1.2900       1.1645       0.2500       1.1375   \n",
       "4       0.1975       0.1975        0.585       1.1515       0.9795       0.1975       0.8175   \n",
       "\n",
       "   Rings  \n",
       "0     11  \n",
       "1     11  \n",
       "2      6  \n",
       "3     10  \n",
       "4      9  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openfe import OpenFE, transform\n",
    "\n",
    "ofe = OpenFE()\n",
    "features = ofe.fit(data=train.drop('Rings', axis=1), label=train['Rings'], feature_boosting=True, n_jobs=8, task='regression', metric='rmse', n_data_blocks=512)\n",
    "train_x, test_x = transform(train.drop('Rings', axis=1), test, features, n_jobs=8)\n",
    "\n",
    "train_x.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([train_x, train['Rings']], axis=1)\n",
    "test = test_x.copy()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Rings = np.log1p(train.Rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240420_171305\"\n",
      "Presets specified: ['medium_quality']\n",
      "Beginning AutoGluon training ... Time limit = 57600s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240420_171305\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.1b20240321\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       6.49 GB / 15.42 GB (42.1%)\n",
      "Disk Space Avail:   529.53 GB / 931.51 GB (56.8%)\n",
      "===================================================\n",
      "Train Data Rows:    94792\n",
      "Train Data Columns: 86\n",
      "Label Column:       Rings\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6639.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 61.83 MB (0.9% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 5): ['autoFE_f_31', 'autoFE_f_65', 'autoFE_f_68', 'autoFE_f_71', 'autoFE_f_76']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 5 | ['autoFE_f_31', 'autoFE_f_65', 'autoFE_f_68', 'autoFE_f_71', 'autoFE_f_76']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 80 | ['Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', ...]\n",
      "\t\t('int', [])   :  1 | ['Sex']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 80 | ['Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', ...]\n",
      "\t\t('int', [])   :  1 | ['Sex']\n",
      "\t1.0s = Fit runtime\n",
      "\t81 features in original data used to generate 81 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 58.22 MB (0.9% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_squared_log_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 3 stack levels (L1 to L3) ...\n",
      "Included models: ['XGB', 'CAT', 'GBM', 'XT', 'RF'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 25593.11s of the 57598.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=6.10%)\n",
      "\t-0.0446\t = Validation score   (-mean_squared_log_error)\n",
      "\t70.45s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 25506.26s of the 57512.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=6.97%)\n",
      "\t-0.0445\t = Validation score   (-mean_squared_log_error)\n",
      "\t64.68s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 25437.15s of the 57442.93s of remaining time.\n",
      "\t-0.0452\t = Validation score   (-mean_squared_log_error)\n",
      "\t292.0s\t = Training   runtime\n",
      "\t5.95s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 25137.81s of the 57143.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=7.94%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t101.45s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 25031.92s of the 57037.7s of remaining time.\n",
      "\t-0.045\t = Validation score   (-mean_squared_log_error)\n",
      "\t121.35s\t = Training   runtime\n",
      "\t5.7s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 24903.28s of the 56909.06s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.21% memory usage per fold, 40.85%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=10.21%)\n",
      "\t-0.0445\t = Validation score   (-mean_squared_log_error)\n",
      "\t57.6s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 24841.31s of the 56847.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=8.41%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t121.84s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 2559.31s of the 56720.7s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.333, 'LightGBMLarge_BAG_L1': 0.333, 'ExtraTreesMSE_BAG_L1': 0.111, 'XGBoost_BAG_L1': 0.111, 'LightGBM_BAG_L1': 0.056, 'RandomForestMSE_BAG_L1': 0.056}\n",
      "\t-0.0443\t = Validation score   (-mean_squared_log_error)\n",
      "\t2.83s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Included models: ['XGB', 'CAT', 'GBM', 'XT', 'RF'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 37802.44s of the 56717.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=7.43%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t53.89s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 37744.24s of the 56659.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=7.68%)\n",
      "\t-0.0443\t = Validation score   (-mean_squared_log_error)\n",
      "\t52.93s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 37686.93s of the 56602.3s of remaining time.\n",
      "\t-0.0447\t = Validation score   (-mean_squared_log_error)\n",
      "\t409.87s\t = Training   runtime\n",
      "\t6.42s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 37268.78s of the 56184.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=8.15%)\n",
      "\t-0.0443\t = Validation score   (-mean_squared_log_error)\n",
      "\t52.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 37211.79s of the 56127.17s of remaining time.\n",
      "\t-0.0446\t = Validation score   (-mean_squared_log_error)\n",
      "\t168.58s\t = Training   runtime\n",
      "\t6.13s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 37034.88s of the 55950.24s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.84% memory usage per fold, 47.37%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=11.84%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t48.18s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 36982.07s of the 55897.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=9.45%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t118.49s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 3780.24s of the 55774.5s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.273, 'LightGBMXT_BAG_L2': 0.182, 'LightGBM_BAG_L2': 0.182, 'ExtraTreesMSE_BAG_L2': 0.182, 'RandomForestMSE_BAG_L2': 0.091, 'XGBoost_BAG_L2': 0.091}\n",
      "\t-0.0443\t = Validation score   (-mean_squared_log_error)\n",
      "\t3.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Included models: ['XGB', 'CAT', 'GBM', 'XT', 'RF'] (Specified by `included_model_types`, all other model types will be skipped)\n",
      "Fitting 7 L3 models ...\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 55771.28s of the 55771.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=7.70%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t55.41s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 55711.0s of the 55710.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=7.14%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t53.47s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L3 ... Training model for up to 55653.31s of the 55653.28s of remaining time.\n",
      "\t-0.0449\t = Validation score   (-mean_squared_log_error)\n",
      "\t441.63s\t = Training   runtime\n",
      "\t6.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 55204.75s of the 55204.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=7.86%)\n",
      "\t-0.0444\t = Validation score   (-mean_squared_log_error)\n",
      "\t49.34s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ... Training model for up to 55151.21s of the 55151.18s of remaining time.\n",
      "\t-0.0448\t = Validation score   (-mean_squared_log_error)\n",
      "\t146.02s\t = Training   runtime\n",
      "\t5.73s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 54998.42s of the 54998.39s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.04% memory usage per fold, 40.15%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=10.04%)\n",
      "\t-0.0445\t = Validation score   (-mean_squared_log_error)\n",
      "\t45.62s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 54948.52s of the 54948.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=8, gpus=1, memory=8.09%)\n",
      "\t-0.0445\t = Validation score   (-mean_squared_log_error)\n",
      "\t102.53s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 5577.13s of the 54841.26s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.227, 'LightGBMLarge_BAG_L1': 0.182, 'CatBoost_BAG_L2': 0.182, 'ExtraTreesMSE_BAG_L2': 0.136, 'RandomForestMSE_BAG_L2': 0.091, 'XGBoost_BAG_L2': 0.091, 'LightGBM_BAG_L2': 0.045, 'ExtraTreesMSE_BAG_L3': 0.045}\n",
      "\t-0.0443\t = Validation score   (-mean_squared_log_error)\n",
      "\t6.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2765.31s ... Best model: \"WeightedEnsemble_L4\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240420_171305\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x14502277b80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from custom_metrics import rmsle_scorer\n",
    "\n",
    "time_limit = 3600*16\n",
    "\n",
    "automl = TabularPredictor(label='Rings', problem_type='regression',\n",
    "                          eval_metric=rmsle_scorer\n",
    "                          )\n",
    "\n",
    "automl.fit(train, presets='medium_quality', time_limit=time_limit, num_bag_folds=8, num_bag_sets=0, num_stack_levels=2, dynamic_stacking=False, \n",
    "            included_model_types=['XGB', 'CAT', 'GBM', 'XT', 'RF'], ag_args_fit={'num_gpus': 1, 'num_cpus': 8},\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>-0.044251</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>32.427107</td>\n",
       "      <td>1885.998389</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>6.068096</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-0.044276</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>26.423582</td>\n",
       "      <td>1618.608454</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>3.186564</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.044288</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>12.777632</td>\n",
       "      <td>761.739867</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>2.826576</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-0.044342</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>13.108655</td>\n",
       "      <td>881.966281</td>\n",
       "      <td>0.053005</td>\n",
       "      <td>52.602862</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-0.044347</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>13.187657</td>\n",
       "      <td>882.296598</td>\n",
       "      <td>0.132007</td>\n",
       "      <td>52.933179</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_BAG_L3</td>\n",
       "      <td>-0.044375</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>26.745604</td>\n",
       "      <td>1783.254404</td>\n",
       "      <td>0.051001</td>\n",
       "      <td>49.344402</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L3</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>26.897600</td>\n",
       "      <td>1789.319443</td>\n",
       "      <td>0.202998</td>\n",
       "      <td>55.409440</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-0.044385</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>13.210649</td>\n",
       "      <td>883.253505</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>53.890086</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_BAG_L3</td>\n",
       "      <td>-0.044407</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>26.829609</td>\n",
       "      <td>1787.378722</td>\n",
       "      <td>0.135006</td>\n",
       "      <td>53.468720</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-0.044407</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>0.315989</td>\n",
       "      <td>121.840561</td>\n",
       "      <td>0.315989</td>\n",
       "      <td>121.840561</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-0.044439</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>0.066971</td>\n",
       "      <td>101.452773</td>\n",
       "      <td>0.066971</td>\n",
       "      <td>101.452773</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-0.044441</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>13.524945</td>\n",
       "      <td>877.546118</td>\n",
       "      <td>0.469295</td>\n",
       "      <td>48.182698</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>-0.044448</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>13.329668</td>\n",
       "      <td>947.851532</td>\n",
       "      <td>0.274018</td>\n",
       "      <td>118.488113</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost_BAG_L3</td>\n",
       "      <td>-0.044466</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>27.152584</td>\n",
       "      <td>1779.525600</td>\n",
       "      <td>0.457981</td>\n",
       "      <td>45.615597</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-0.044503</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>0.223002</td>\n",
       "      <td>64.676132</td>\n",
       "      <td>0.223002</td>\n",
       "      <td>64.676132</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LightGBMLarge_BAG_L3</td>\n",
       "      <td>-0.044533</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>26.923599</td>\n",
       "      <td>1836.444915</td>\n",
       "      <td>0.228997</td>\n",
       "      <td>102.534913</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-0.044547</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>0.524826</td>\n",
       "      <td>57.597555</td>\n",
       "      <td>0.524826</td>\n",
       "      <td>57.597555</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-0.044585</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>0.282001</td>\n",
       "      <td>70.450129</td>\n",
       "      <td>0.282001</td>\n",
       "      <td>70.450129</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-0.044606</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>19.189541</td>\n",
       "      <td>997.939651</td>\n",
       "      <td>6.133892</td>\n",
       "      <td>168.576232</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-0.044743</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>19.477386</td>\n",
       "      <td>1239.236833</td>\n",
       "      <td>6.421736</td>\n",
       "      <td>409.873413</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreesMSE_BAG_L3</td>\n",
       "      <td>-0.044776</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>32.423132</td>\n",
       "      <td>1879.930294</td>\n",
       "      <td>5.728529</td>\n",
       "      <td>146.020291</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestMSE_BAG_L3</td>\n",
       "      <td>-0.044917</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>32.812200</td>\n",
       "      <td>2175.542247</td>\n",
       "      <td>6.117598</td>\n",
       "      <td>441.632245</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-0.045008</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>5.696826</td>\n",
       "      <td>121.346155</td>\n",
       "      <td>5.696826</td>\n",
       "      <td>121.346155</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-0.045175</td>\n",
       "      <td>mean_squared_log_error</td>\n",
       "      <td>5.946035</td>\n",
       "      <td>292.000115</td>\n",
       "      <td>5.946035</td>\n",
       "      <td>292.000115</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_val             eval_metric  pred_time_val     fit_time  \\\n",
       "0      WeightedEnsemble_L4  -0.044251  mean_squared_log_error      32.427107  1885.998389   \n",
       "1      WeightedEnsemble_L3  -0.044276  mean_squared_log_error      26.423582  1618.608454   \n",
       "2      WeightedEnsemble_L2  -0.044288  mean_squared_log_error      12.777632   761.739867   \n",
       "3          CatBoost_BAG_L2  -0.044342  mean_squared_log_error      13.108655   881.966281   \n",
       "4          LightGBM_BAG_L2  -0.044347  mean_squared_log_error      13.187657   882.296598   \n",
       "5          CatBoost_BAG_L3  -0.044375  mean_squared_log_error      26.745604  1783.254404   \n",
       "6        LightGBMXT_BAG_L3  -0.044381  mean_squared_log_error      26.897600  1789.319443   \n",
       "7        LightGBMXT_BAG_L2  -0.044385  mean_squared_log_error      13.210649   883.253505   \n",
       "8          LightGBM_BAG_L3  -0.044407  mean_squared_log_error      26.829609  1787.378722   \n",
       "9     LightGBMLarge_BAG_L1  -0.044407  mean_squared_log_error       0.315989   121.840561   \n",
       "10         CatBoost_BAG_L1  -0.044439  mean_squared_log_error       0.066971   101.452773   \n",
       "11          XGBoost_BAG_L2  -0.044441  mean_squared_log_error      13.524945   877.546118   \n",
       "12    LightGBMLarge_BAG_L2  -0.044448  mean_squared_log_error      13.329668   947.851532   \n",
       "13          XGBoost_BAG_L3  -0.044466  mean_squared_log_error      27.152584  1779.525600   \n",
       "14         LightGBM_BAG_L1  -0.044503  mean_squared_log_error       0.223002    64.676132   \n",
       "15    LightGBMLarge_BAG_L3  -0.044533  mean_squared_log_error      26.923599  1836.444915   \n",
       "16          XGBoost_BAG_L1  -0.044547  mean_squared_log_error       0.524826    57.597555   \n",
       "17       LightGBMXT_BAG_L1  -0.044585  mean_squared_log_error       0.282001    70.450129   \n",
       "18    ExtraTreesMSE_BAG_L2  -0.044606  mean_squared_log_error      19.189541   997.939651   \n",
       "19  RandomForestMSE_BAG_L2  -0.044743  mean_squared_log_error      19.477386  1239.236833   \n",
       "20    ExtraTreesMSE_BAG_L3  -0.044776  mean_squared_log_error      32.423132  1879.930294   \n",
       "21  RandomForestMSE_BAG_L3  -0.044917  mean_squared_log_error      32.812200  2175.542247   \n",
       "22    ExtraTreesMSE_BAG_L1  -0.045008  mean_squared_log_error       5.696826   121.346155   \n",
       "23  RandomForestMSE_BAG_L1  -0.045175  mean_squared_log_error       5.946035   292.000115   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0                 0.003976           6.068096            4       True         24  \n",
       "1                 0.002997           3.186564            3       True         16  \n",
       "2                 0.003983           2.826576            2       True          8  \n",
       "3                 0.053005          52.602862            2       True         12  \n",
       "4                 0.132007          52.933179            2       True         10  \n",
       "5                 0.051001          49.344402            3       True         20  \n",
       "6                 0.202998          55.409440            3       True         17  \n",
       "7                 0.155000          53.890086            2       True          9  \n",
       "8                 0.135006          53.468720            3       True         18  \n",
       "9                 0.315989         121.840561            1       True          7  \n",
       "10                0.066971         101.452773            1       True          4  \n",
       "11                0.469295          48.182698            2       True         14  \n",
       "12                0.274018         118.488113            2       True         15  \n",
       "13                0.457981          45.615597            3       True         22  \n",
       "14                0.223002          64.676132            1       True          2  \n",
       "15                0.228997         102.534913            3       True         23  \n",
       "16                0.524826          57.597555            1       True          6  \n",
       "17                0.282001          70.450129            1       True          1  \n",
       "18                6.133892         168.576232            2       True         13  \n",
       "19                6.421736         409.873413            2       True         11  \n",
       "20                5.728529         146.020291            3       True         21  \n",
       "21                6.117598         441.632245            3       True         19  \n",
       "22                5.696826         121.346155            1       True          5  \n",
       "23                5.946035         292.000115            1       True          3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = automl.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predictions.reset_index().rename(columns={0: 'Rings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Rings = np.expm1(submission.Rings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Rings = np.clip(submission.Rings, 1, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.58127"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.Rings.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
